graph TD
    subgraph "整体流程：自监督训练"
        direction TB
        
        subgraph " "
             Input_Sequence["输入序列<br/>(batch, 200, 11)"]
        end

        subgraph Encoder [编码器 Encoder]
            direction TB
            EncoderLSTM["LSTM 层<br/><i>逐时间步处理序列<br/>压缩信息</i>"]
            Context["上下文向量 (Context Vector)<br/><i>最终的 Hidden & Cell State</i>"]
            Input_Sequence --> EncoderLSTM
            EncoderLSTM --> Context
        end
        
        subgraph " "
            FeatureVector["<b>我们需要的特征向量</b><br/>(发往服务器)<br/>(batch, hidden_dim)"]
        end

        Context -- "作为特征提取" --> FeatureVector

        subgraph Decoder [解码器 Decoder]
            direction TB
            DecoderLSTM["LSTM 层<br/><i>继承上下文向量作为初始状态</i>"]
            Loop["<br><i>(自回归循环 100 次)</i>"]
            FCLayer["全连接层 (Linear)<br/><i>映射到输出维度 (11)</i>"]
            
            Context -- "初始化解码器" --> DecoderLSTM
            DecoderLSTM --> FCLayer
            FCLayer --> Output_Vector_t["预测的单个时间点<br/>(batch, 1, 11)"]
            
            Output_Vector_t -- "收集预测" --> Loop
            Output_Vector_t -. "作为下一步的输入" .-> DecoderLSTM
        end

        subgraph " "
             Output_Sequence["最终预测序列<br/>(batch, 100, 11)"]
        end

        Loop --> Output_Sequence
    end

    style Encoder fill:#D6EAF8,stroke:#5DADE2
    style Decoder fill:#D5F5E3,stroke:#58D68D
    style FeatureVector fill:#FCF3CF,stroke:#F4D03F,stroke-width:2px