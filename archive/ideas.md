## 特征模型（部署于边缘节点）

这个模型的核心目标是：**高效、轻量、并能提取出对时序任务有用的压缩特征**。由于特征无需人类可解释，我们可以大胆选用一些深度学习方法。

### 核心思路
将一小段时间窗口（例如2-3秒）的传感器数据作为一个输入样本，输出一个固定维度的特征向量。

### 基于一维卷积神经网络 (1D-CNN) 的方案

* **架构**:
    1.  **输入层**: 输入为形状为 `(窗口长度, 传感器数量)` 的矩阵。例如，采样频率为50Hz，窗口为2秒，有6个传感器（如三轴加速度+三轴陀螺仪），则输入形状为 `(100, 6)`。
    2.  **卷积层**: 使用多个一维卷积层（`Conv1D`）。卷积核会在时间维度上滑动，非常适合捕捉传感器数据中的局部模式（例如，跌倒瞬间的剧烈冲击、失重阶段的平滑等）。
    3.  **激活与池化**: 每个卷积层后跟一个激活函数（如 ReLU）和一个池化层（如 `MaxPooling1D` 或 `AveragePooling1D`）。池化层可以降低数据维度，增大感受野，并提供一定的平移不变性。
    4.  **Flatten与输出**: 最后将多层卷积和池化后的结果展平（Flatten），可以再接一个全连接层（Dense），最终输出一个压缩的特征向量（例如128维）。

* **优点**:
    * **计算高效**: 卷积操作可以并行计算，非常适合在资源受限的边缘设备上运行。
    * **参数量少**: 相比于RNN，CNN的参数共享机制使其更轻量。
    * **特征提取能力强**: 能有效捕捉信号的“形态”特征。


-----


## 保真模型（部署于总服务器）

### 核心设计思想：双流输入，动态融合

所有方案都基于一个共同的架构：模型有两个输入“分支”，一个处理来自**历史特征池**的序列，另一个处理来自**历史传感器数据池**的数据。关键的区别在于它们如何“融合”信息。

### 门控融合网络 (Gated Fusion Network)

通过一个可学习的“门”来动态控制信息流的权重，能优雅地处理原始数据缺失的情况。

### 工作原理

模型的核心是一个循环神经网络（如LSTM或GRU），它负责处理连续的边缘特征，维持一个“记忆状态”。当有高保真的原始数据传来时，模型通过一个“门控单元”来决定应该在多大程度上采纳这些新信息来修正自己的状态。

### 模型结构

1.  **特征流处理器 (Feature Stream Processor)**:

      * 使用一个 **LSTM** 或 **GRU** 来处理来自“历史特征池”的特征序列（例如，过去30秒内每0.5秒一个的特征向量）。
      * 这个LSTM的\*\*隐藏状态（Hidden State）\*\*是整个模型的核心，它代表了到目前为止对用户状态的连续追踪和理解。

2.  **原始数据处理器 (Raw Data Processor)**:

      * 当采样模型决定同步数据时，我们会得到一小段原始传感器数据（例如4秒的`[200, 11]`数据）。
      * 使用一个**1D-CNN**（结构可以和您的特征模型类似）来处理这段原始数据，将其编码成一个高信息量的特征向量，我们称之为 `V_raw`。

3.  **门控融合单元 (Gating Unit)**:

      * **输入**: 将LSTM在当前时间步的输出 `Output_lstm` 和 `V_raw` 拼接起来。
      * **门计算**: 将拼接后的向量送入一个全连接层，并用`Sigmoid`激活函数计算出一个“门控值” `g` (介于0和1之间)。
          * `g = sigmoid(Linear(concat(Output_lstm, V_raw)))`
      * **信息融合**: 使用门控值 `g` 来加权融合两个信息源。
          * `Fused_vector = g * Output_lstm + (1 - g) * V_raw`
      * **处理数据缺失**: 如果当前时间步**没有**对应的原始数据，我们可以将 `V_raw` 作为一个全零向量输入。门控单元会很快学会，当 `V_raw` 为零时，让 `g` 趋近于1，从而忽略 `V_raw` 的影响，只依赖LSTM自身的状态。

4.  **分类器 (Classifier)**:

      * 将最终的 `Fused_vector` 送入一个或多个全连接层，进行最终的跌倒/非跌倒判断。

### 状态特征 (`State Feature`) 的提供

这个结构天然地产生了一个完美的“状态特征”：**LSTM的隐藏状态 (Hidden State)**。这个隐藏状态 `h_t` 包含了历史特征序列的全部精华，是RL采样模型判断“当前信息是否充足”的理想输入。

### 优点

  * **鲁棒性强**：能优雅、自动地处理原始数据的稀疏性问题。
  * **解释性较好**：可以分析门控值 `g` 的大小，了解模型在决策时更依赖历史趋势还是瞬时高保真数据。
  * **实现简单**：相比更复杂的机制，门控融合的逻辑清晰，易于实现。
