{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "110beca1",
   "metadata": {},
   "source": [
    "## 整体思路\n",
    "\n",
    "1.  **数据源 (Data Source)**: 按照50Hz的频率，逐个“吐出”数据点，模拟传感器实时产生数据。\n",
    "2.  **边缘节点 (Edge Node)**: 接收数据点，维护一个滑动窗口，并按设定的时间间隔进行模型推理，生成特征和实时判断，并将特征分批保存。\n",
    "\n",
    "#### 关键设计决策：\n",
    "\n",
    "  * **数据流的重建**：数据 `(9491, 200, 11)` 是一个已经切分好的序列集合。为了模拟真实的连续数据流，我们需要将其“展开”成一个长的一维时间序列。假设这些序列是步长为1生成的，那么原始数据流的长度大约是 `9491 - 1 + 200 = 9690` 个时间点。我们的模拟器会从这个重建的流中逐个读取数据。\n",
    "  * **处理间隔（步长）**：我们之前讨论过，滑动窗口的步长是关键。一个**0.5秒（25个样本点）的步长是一个很好的起点，它在实时性和计算负载之间取得了很好的平衡。这意味着边缘节点每秒会进行2次推理**。\n",
    "  * **特征文件保存**：为了模拟“实时生成特征文件”，我们不会等所有数据处理完再保存。而是每当边缘节点生成了一定数量（例如100个）的特征后，就将其保存为一个独立的文件（`features_batch_0.npy`, `features_batch_1.npy`, ...），这更贴近真实场景。\n",
    "\n",
    "\n",
    "**每生成100个特征，总共对应消耗了 `2675` 条原始数据。**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b885b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, deque\n",
    "import re\n",
    "import io\n",
    "import joblib\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea85e2e",
   "metadata": {},
   "source": [
    "## 定义模型和节点、数据加载模拟器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "226c2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureModel1DCNN(nn.Module):\n",
    "    def __init__(self, input_channels=11, num_classes=1):\n",
    "        super(FeatureModel1DCNN, self).__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=input_channels, out_channels=64, kernel_size=3, padding='same'), nn.ReLU(), nn.BatchNorm1d(64),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding='same'), nn.ReLU(), nn.BatchNorm1d(128),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding='same'), nn.ReLU(), nn.BatchNorm1d(256),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 25, 512), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        features = self.feature_extractor(x)\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        features = self.feature_extractor(x)\n",
    "        return features\n",
    "\n",
    "# --- 模拟器核心代码 ---\n",
    "\n",
    "class DataSourceSimulator:\n",
    "    \"\"\"\n",
    "    模拟一个实时数据源，从一个大的序列集合中重建并逐个吐出数据点。\n",
    "    \"\"\"\n",
    "    def __init__(self, sequences_array, sampling_rate_hz=50):\n",
    "        print(\"Data Source: Reconstructing continuous data stream from sequences...\")\n",
    "        # 从 (N, 200, 11) 的序列中重建原始的连续数据流\n",
    "        # 第一个序列是 [P0..P199], 第二个是 [P1..P200], ...\n",
    "        # 因此，连续数据流是 [P0..P199] + [P200] + [P201] + ...\n",
    "        self.continuous_data = sequences_array[0] # 以第一个完整序列开始\n",
    "        additional_points = sequences_array[1:, -1, :] # 从第二个序列开始，只取最后一个新数据点\n",
    "        self.continuous_data = np.vstack((self.continuous_data, additional_points))\n",
    "        \n",
    "        self.sampling_period_s = 1.0 / sampling_rate_hz\n",
    "        self.total_points = len(self.continuous_data)\n",
    "        self._current_index = 0\n",
    "        print(f\"Data Source: Stream reconstructed. Total points: {self.total_points}.\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._current_index < self.total_points:\n",
    "            data_point = self.continuous_data[self._current_index]\n",
    "            timestamp = self._current_index * self.sampling_period_s\n",
    "            self._current_index += 1\n",
    "            return timestamp, data_point\n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "class EdgeNodeSimulator:\n",
    "    \"\"\"\n",
    "    模拟边缘节点的行为：接收数据，用滑动窗口处理，并实时生成特征和判断。\n",
    "    \"\"\"\n",
    "    def __init__(self, model, scaler, device, window_size, step_size, feature_batch_size=100, output_dir=\"features\"):\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.device = device\n",
    "        self.WINDOW_SIZE = window_size\n",
    "        self.STEP_SIZE = step_size\n",
    "        self.FEATURE_BATCH_SIZE = feature_batch_size\n",
    "        self.OUTPUT_DIR = output_dir\n",
    "\n",
    "        self.buffer = deque(maxlen=self.WINDOW_SIZE)\n",
    "        self.points_since_last_inference = 0\n",
    "        \n",
    "        self.feature_batch = []\n",
    "        self.feature_files_saved = 0\n",
    "        \n",
    "        if not os.path.exists(self.OUTPUT_DIR):\n",
    "            os.makedirs(self.OUTPUT_DIR)\n",
    "\n",
    "    def _preprocess(self, window_data):\n",
    "        scaled_window = self.scaler.transform(window_data)\n",
    "        return torch.tensor(scaled_window, dtype=torch.float32).unsqueeze(0).to(self.device)\n",
    "\n",
    "    def _save_feature_batch(self):\n",
    "        if not self.feature_batch:\n",
    "            return\n",
    "        \n",
    "        save_path = os.path.join(self.OUTPUT_DIR, f\"features_batch_{self.feature_files_saved}.npy\")\n",
    "        np.save(save_path, np.vstack(self.feature_batch))\n",
    "        print(f\"\\n--- Saved {len(self.feature_batch)} features to {save_path} ---\\n\")\n",
    "        \n",
    "        self.feature_batch = []\n",
    "        self.feature_files_saved += 1\n",
    "        \n",
    "    def process_data_point(self, timestamp, data_point):\n",
    "        self.buffer.append(data_point)\n",
    "        self.points_since_last_inference += 1\n",
    "        \n",
    "        # 1. 检查缓冲区是否已满\n",
    "        if len(self.buffer) < self.WINDOW_SIZE:\n",
    "            return # 继续收集数据\n",
    "        \n",
    "        # 2. 检查是否到达下一个推理时间点 (步长)\n",
    "        if self.points_since_last_inference >= self.STEP_SIZE:\n",
    "            self.points_since_last_inference = 0 # 重置计数器\n",
    "            \n",
    "            # 准备数据并进行推理\n",
    "            current_window = np.array(self.buffer)\n",
    "            window_tensor = self._preprocess(current_window)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                features = self.model.extract_features(window_tensor)\n",
    "                logits = self.model(window_tensor)\n",
    "            \n",
    "            # 处理结果\n",
    "            confidence = torch.sigmoid(logits).item()\n",
    "            prediction = \"FALL DETECTED!\" if confidence > 0.5 else \"No Fall\"\n",
    "            \n",
    "            # 打印实时判断日志\n",
    "            print(f\"Timestamp: {timestamp:7.2f}s | Confidence: {confidence:.4f} | Prediction: {prediction}\")\n",
    "            \n",
    "            # 收集特征，准备分批保存\n",
    "            self.feature_batch.append(features.cpu().numpy().flatten())\n",
    "            if len(self.feature_batch) >= self.FEATURE_BATCH_SIZE:\n",
    "                self._save_feature_batch()\n",
    "\n",
    "    def finalize(self):\n",
    "        \"\"\"在数据流结束后，保存剩余的特征。\"\"\"\n",
    "        self._save_feature_batch()\n",
    "        print(\"Simulation finished. All remaining features saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f25aed5",
   "metadata": {},
   "source": [
    "## 获取并清理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e4b4ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for data in: MobiFall_Dataset\n",
      "\n",
      "Processing and combining 627 unique trials...\n",
      "Successfully processed and combined sensor data for 627 trials.\n",
      "Created (9491, 200, 11) sequences.\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = 'MobiFall_Dataset'\n",
    "TARGET_SAMPLING_RATE_HZ = 50.0  # Target sampling rate in Hz\n",
    "TARGET_SAMPLING_PERIOD = f\"{int(1000 / TARGET_SAMPLING_RATE_HZ)}ms\"\n",
    "SEQUENCE_LENGTH = int(TARGET_SAMPLING_RATE_HZ * 4) # 200 samples for 4 seconds at 50Hz\n",
    "STEP = int(TARGET_SAMPLING_RATE_HZ * 1)          # 50 samples for 1 second step at 50Hz\n",
    "\n",
    "SENSOR_CODES = [\"acc\", \"gyro\", \"ori\"]\n",
    "EXPECTED_COLUMNS = {\n",
    "    \"acc\": [\"acc_x\", \"acc_y\", \"acc_z\"],\n",
    "    \"gyro\": [\"gyro_x\", \"gyro_y\", \"gyro_z\"],\n",
    "    \"ori\": [\"ori_azimuth\", \"ori_pitch\", \"ori_roll\"]\n",
    "}\n",
    "ALL_FEATURE_COLUMNS = [\n",
    "    \"acc_x\", \"acc_y\", \"acc_z\", \"acc_smv\",\n",
    "    \"gyro_x\", \"gyro_y\", \"gyro_z\", \"gyro_smv\",\n",
    "    \"ori_azimuth\", \"ori_pitch\", \"ori_roll\"\n",
    "]\n",
    "\n",
    "\n",
    "def load_and_resample_sensor_file(filepath, sensor_code):\n",
    "    \"\"\"加载单个传感器文件，转换时间戳并进行重采样。\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        # 初始化一个变量作为“标记未找到”的标志\n",
    "        data_start_line_index = -1\n",
    "\n",
    "        # 遍历文件中的每一行\n",
    "        for i, line in enumerate(lines):\n",
    "            # 检查当前行是否是\"@DATA\"标记\n",
    "            if line.strip().upper() == \"@DATA\":\n",
    "                # 如果是，则记录下一行的行号并跳出循环\n",
    "                data_start_line_index = i + 1\n",
    "                break\n",
    "\n",
    "        # 检查标记是否被找到\n",
    "        if data_start_line_index == -1 or data_start_line_index >= len(lines):\n",
    "            return None\n",
    "\n",
    "        # 将数据行拼接成单个字符串\n",
    "        data_string = \"\".join(lines[data_start_line_index:])\n",
    "\n",
    "        # 检查字符串是否为空\n",
    "        if not data_string.strip():\n",
    "            return None\n",
    "\n",
    "        # 使用pandas处理数据\n",
    "        df = pd.read_csv(io.StringIO(data_string), header=None, usecols=[0, 1, 2, 3])\n",
    "        \n",
    "        # 检查生成的数据表是否为空\n",
    "        if df.empty:\n",
    "            return None\n",
    "\n",
    "        # 为数据列进行命名\n",
    "        df.columns = ['timestamp_ns'] + EXPECTED_COLUMNS[sensor_code]\n",
    "\n",
    "        # 将ns时间戳转换为标准的日期时间格式\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp_ns'], unit='ns')\n",
    "\n",
    "        # 将新的日期时间设置为索引，并删除旧的时间戳列\n",
    "        df = df.set_index('timestamp').drop(columns=['timestamp_ns'])\n",
    "\n",
    "        # 按时间索引进行排序\n",
    "        df = df.sort_index()\n",
    "\n",
    "        # 将采样时间不均匀的传感器数据，强制转换为频率统一（每20毫秒一个点）的规整数据流，并填补其中的所有空白\n",
    "        df_resampled = df.resample(TARGET_SAMPLING_PERIOD).mean().interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "        # 检查当前处理的传感器是否为加速度计 ('acc')\n",
    "        if sensor_code == 'acc':\n",
    "            # 安全性检查 - 确认三轴数据都存在\n",
    "            if all(col in df_resampled.columns for col in ['acc_x', 'acc_y', 'acc_z']):\n",
    "                # 计算信号幅值向量 (SMV)\n",
    "                df_resampled['acc_smv'] = np.sqrt(\n",
    "                    df_resampled['acc_x']**2 + df_resampled['acc_y']**2 + df_resampled['acc_z']**2\n",
    "                )\n",
    "\n",
    "        # 如果不是加速度计，则检查是否为陀螺仪 ('gyro')\n",
    "        elif sensor_code == 'gyro':\n",
    "            # 对陀螺仪数据执行相同的操作\n",
    "            if all(col in df_resampled.columns for col in ['gyro_x', 'gyro_y', 'gyro_z']):\n",
    "                df_resampled['gyro_smv'] = np.sqrt(\n",
    "                    df_resampled['gyro_x']**2 + df_resampled['gyro_y']**2 + df_resampled['gyro_z']**2\n",
    "                )\n",
    "\n",
    "        return df_resampled\n",
    "\n",
    "    except (pd.errors.EmptyDataError, ValueError):\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {filepath}: {e}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "def load_data_from_structured_folders(dataset_root_path):\n",
    "    \"\"\"遍历数据集文件夹，处理、对齐并组合每个试验的传感器数据。\"\"\"\n",
    "    print(f\"Scanning for data in: {dataset_root_path}\")\n",
    "    if not os.path.isdir(dataset_root_path):\n",
    "        print(f\"ERROR: Dataset root path '{dataset_root_path}' not found.\")\n",
    "        return [], []\n",
    "\n",
    "    # 存放每一次活动试验（trial）所对应的各个传感器文件的路径（数据文件的位置）\n",
    "    trial_sensor_files_map = defaultdict(lambda: defaultdict(str))\n",
    "\n",
    "    # 存放每一次活动试验的元数据（这些数据代表什么，即标签信息）\n",
    "    trial_metadata_map = {}\n",
    "    \n",
    "    # 遍历数据集的每一个文件夹\n",
    "    for dirpath, _, filenames in os.walk(dataset_root_path):\n",
    "        # 解析文件夹路径，以确定活动类别和具体活动\n",
    "        relative_path = os.path.relpath(dirpath, dataset_root_path)\n",
    "        path_parts = relative_path.split(os.sep)\n",
    "        # 确保只处理包含实际数据文件的特定层级文件夹\n",
    "        if len(path_parts) != 3: continue\n",
    "\n",
    "        # 遍历这些特定文件夹中的每一个文件\n",
    "        for filename in filenames:\n",
    "            # 确保只处理.txt文件\n",
    "            if not filename.endswith(\".txt\"): continue\n",
    "            \n",
    "            # 解析文件名，通过下划线分割以获取各个部分\n",
    "            fname_parts = filename.replace('.txt', '').split('_')\n",
    "            # 过滤掉不符合预期格式的文件名\n",
    "            if len(fname_parts) != 4: continue\n",
    "            \n",
    "            # 从文件名部分中提取所需信息\n",
    "            _, sensor_code, _, trial_no_str = fname_parts\n",
    "            # 将传感器代码转为小写以保持一致性\n",
    "            sensor_code = sensor_code.lower()\n",
    "            # 确保是已知的传感器类型 ('acc', 'gyro', 'ori')\n",
    "            if sensor_code not in SENSOR_CODES: continue\n",
    "\n",
    "            # 尝试从路径和文件名中提取并转换所有元数据\n",
    "            try:\n",
    "                # 从文件夹路径的第一部分提取受试者ID\n",
    "                subject_match = re.fullmatch(r'sub(\\d+)', path_parts[0], re.IGNORECASE)\n",
    "                if not subject_match: continue\n",
    "                subject_id = int(subject_match.group(1))\n",
    "                \n",
    "                # 从文件夹路径的第二和第三部分获取类别和活动代码\n",
    "                category = path_parts[1].upper()\n",
    "                activity_code = path_parts[2].upper()\n",
    "                # 将试验编号从字符串转换为整数\n",
    "                trial_no = int(trial_no_str)\n",
    "                # 构建完整的文件路径\n",
    "                filepath = os.path.join(dirpath, filename)\n",
    "                \n",
    "                # 创建一个唯一的键来标识这次试验 (受试者, 活动, 试验编号)\n",
    "                trial_key = (subject_id, activity_code, trial_no)\n",
    "                # 在映射表中存储该传感器文件的路径\n",
    "                trial_sensor_files_map[trial_key][sensor_code] = filepath\n",
    "                # 如果是第一次遇到这个试验，则记录其元数据（类别和活动代码）\n",
    "                if trial_key not in trial_metadata_map:\n",
    "                    trial_metadata_map[trial_key] = {\"category\": category, \"activity_code\": activity_code}\n",
    "            except (AttributeError, ValueError):\n",
    "                # 如果在提取或转换过程中出现任何错误，则跳过该文件\n",
    "                continue\n",
    "\n",
    "    # 初始化两个列表，用于存放最终处理好的数据和对应的标签\n",
    "    processed_trials_data, labels = [], []\n",
    "    print(f\"\\nProcessing and combining {len(trial_sensor_files_map)} unique trials...\")\n",
    "    \n",
    "    # 遍历前面组织好的每一次活动试验（trial）\n",
    "    for trial_key, sensor_files in trial_sensor_files_map.items():\n",
    "        # 确保该次试验包含了 acc, gyro, ori 全部三种传感器文件，否则跳过\n",
    "        if not all(s_code in sensor_files for s_code in SENSOR_CODES): continue\n",
    "\n",
    "        # 使用字典推导式，为每种传感器加载并重采样数据\n",
    "        resampled_dfs = {s_code: load_and_resample_sensor_file(sensor_files[s_code], s_code) for s_code in SENSOR_CODES}\n",
    "        # 如果任何一个文件加载或处理失败（返回了None或空表），则跳过这次试验\n",
    "        if any(df is None or df.empty for df in resampled_dfs.values()): continue\n",
    "\n",
    "        try:\n",
    "            # --- 时间对齐关键步骤 ---\n",
    "            # 找到三个传感器数据中最晚的开始时间\n",
    "            common_start = max(df.index.min() for df in resampled_dfs.values())\n",
    "            # 找到三个传感器数据中最早的结束时间\n",
    "            common_end = min(df.index.max() for df in resampled_dfs.values())\n",
    "            # 如果没有重叠的时间窗口，则跳过\n",
    "            if common_start >= common_end: continue\n",
    "\n",
    "            # 将三个数据表都裁剪到共同的时间范围内\n",
    "            aligned_dfs = [resampled_dfs[s_code][common_start:common_end].reset_index(drop=True) for s_code in SENSOR_CODES]\n",
    "            # 确保对齐后的数据表长度一致且不为空，否则跳过\n",
    "            if not all(len(df) > 0 and len(df) == len(aligned_dfs[0]) for df in aligned_dfs): continue\n",
    "            \n",
    "            # --- 数据合并 ---\n",
    "            # 按列（axis=1）将三个对齐后的数据表拼接成一个宽表\n",
    "            combined_df = pd.concat(aligned_dfs, axis=1)\n",
    "            \n",
    "            # 再次检查并确保列名正确\n",
    "            if len(combined_df.columns) == len(ALL_FEATURE_COLUMNS):\n",
    "                 combined_df.columns = ALL_FEATURE_COLUMNS\n",
    "            else:\n",
    "                 continue # 如果列数不匹配则跳过\n",
    "\n",
    "            # 如果合并后的数据长度不足一个序列窗口（4秒），则跳过\n",
    "            if len(combined_df) < SEQUENCE_LENGTH: continue\n",
    "            \n",
    "            # --- 数据和标签存储 ---\n",
    "            # 将处理好的数据（转换为Numpy数组）存入列表\n",
    "            processed_trials_data.append(combined_df.values)\n",
    "            # 根据元数据判断该试验是\"FALLS\"还是\"ADL\"，并存入标签（1代表跌倒，0代表非跌倒）\n",
    "            labels.append(1 if trial_metadata_map[trial_key][\"category\"] == \"FALLS\" else 0)\n",
    "            \n",
    "        except Exception:\n",
    "            # 捕获任何在对齐和合并过程中可能出现的意外错误，并跳过该试验\n",
    "            continue\n",
    "\n",
    "    print(f\"Successfully processed and combined sensor data for {len(processed_trials_data)} trials.\")\n",
    "    # 返回包含所有处理好的试验数据和标签的列表\n",
    "    return processed_trials_data, labels\n",
    "\n",
    "def create_sequences(data_list, label_list, seq_length, step):\n",
    "    \"\"\"使用滑动窗口从试验数据创建序列。\"\"\"\n",
    "    # 初始化用于存放最终序列和对应标签的列表\n",
    "    X, y = [], []\n",
    "    # 遍历每一次活动试验的数据\n",
    "    for i, trial_data in enumerate(data_list):\n",
    "        trial_label = label_list[i]\n",
    "        # 在单次试验数据上，按指定的步长（step）移动窗口\n",
    "        for j in range(0, len(trial_data) - seq_length + 1, step):\n",
    "            # 截取一个固定长度（seq_length）的片段作为序列\n",
    "            X.append(trial_data[j:(j + seq_length)])\n",
    "            # 为这个序列分配对应的标签\n",
    "            y.append(trial_label)\n",
    "            \n",
    "    if not X: return np.array([]), np.array([])\n",
    "    # 将列表转换为Numpy数组后返回\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "# 1. 加载和创建序列\n",
    "trial_arrays, trial_labels = load_data_from_structured_folders(DATASET_PATH)\n",
    "X_sequences, _ = create_sequences(trial_arrays, trial_labels, SEQUENCE_LENGTH, STEP)\n",
    "print(f\"Created {X_sequences.shape} sequences.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c79f7",
   "metadata": {},
   "source": [
    "## 模拟过程运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a9cf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and scaler...\n",
      "Model loaded from feature_model_1dcnn.pth\n",
      "Scaler loaded from scaler_50hz_torch.gz\n",
      "Loading sequence data...\n",
      "\n",
      "Starting real-time simulation...\n",
      "Data Source: Reconstructing continuous data stream from sequences...\n",
      "Data Source: Stream reconstructed. Total points: 9690.\n",
      "Timestamp:    3.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:    4.48s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:    4.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:    5.48s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:    5.98s | Confidence: 0.0001 | Prediction: No Fall\n",
      "Timestamp:    6.48s | Confidence: 0.8275 | Prediction: FALL DETECTED!\n",
      "Timestamp:    6.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:    7.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:    7.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:    8.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:    8.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:    9.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:    9.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   10.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   10.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   11.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   11.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   12.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   12.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   13.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   13.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   14.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   14.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   15.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   15.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   16.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   16.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   17.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   17.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   18.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   18.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   19.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   19.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   20.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   20.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   21.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   21.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   22.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   22.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   23.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   23.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   24.48s | Confidence: 0.5114 | Prediction: FALL DETECTED!\n",
      "Timestamp:   24.98s | Confidence: 0.6472 | Prediction: FALL DETECTED!\n",
      "Timestamp:   25.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   25.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   26.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   26.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   27.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   27.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   28.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   28.98s | Confidence: 0.0006 | Prediction: No Fall\n",
      "Timestamp:   29.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   29.98s | Confidence: 0.4023 | Prediction: No Fall\n",
      "Timestamp:   30.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   30.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   31.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   31.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   32.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   32.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   33.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   33.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   34.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   34.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   35.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   35.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   36.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   36.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   37.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   37.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   38.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   38.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   39.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   39.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   40.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   40.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   41.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   41.98s | Confidence: 0.7400 | Prediction: FALL DETECTED!\n",
      "Timestamp:   42.48s | Confidence: 0.0001 | Prediction: No Fall\n",
      "Timestamp:   42.98s | Confidence: 0.0116 | Prediction: No Fall\n",
      "Timestamp:   43.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   43.98s | Confidence: 0.0008 | Prediction: No Fall\n",
      "Timestamp:   44.48s | Confidence: 0.2113 | Prediction: No Fall\n",
      "Timestamp:   44.98s | Confidence: 0.7076 | Prediction: FALL DETECTED!\n",
      "Timestamp:   45.48s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   45.98s | Confidence: 0.9999 | Prediction: FALL DETECTED!\n",
      "Timestamp:   46.48s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   46.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   47.48s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   47.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   48.48s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   48.98s | Confidence: 0.9999 | Prediction: FALL DETECTED!\n",
      "Timestamp:   49.48s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   49.98s | Confidence: 0.9998 | Prediction: FALL DETECTED!\n",
      "Timestamp:   50.48s | Confidence: 0.9999 | Prediction: FALL DETECTED!\n",
      "Timestamp:   50.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   51.48s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   51.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   52.48s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   52.98s | Confidence: 0.9990 | Prediction: FALL DETECTED!\n",
      "Timestamp:   53.48s | Confidence: 0.9997 | Prediction: FALL DETECTED!\n",
      "\n",
      "--- Saved 100 features to simulated_features\\features_batch_0.npy ---\n",
      "\n",
      "Timestamp:   53.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   54.48s | Confidence: 0.9999 | Prediction: FALL DETECTED!\n",
      "Timestamp:   54.98s | Confidence: 0.9968 | Prediction: FALL DETECTED!\n",
      "Timestamp:   55.48s | Confidence: 0.6388 | Prediction: FALL DETECTED!\n",
      "Timestamp:   55.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   56.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   56.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   57.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   57.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   58.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   58.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   59.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   59.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   60.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   60.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   61.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   61.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   62.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   62.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   63.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   63.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   64.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   64.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   65.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   65.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   66.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   66.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   67.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   67.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   68.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   68.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   69.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   69.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   70.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   70.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   71.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   71.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   72.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   72.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   73.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   73.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   74.48s | Confidence: 0.0001 | Prediction: No Fall\n",
      "Timestamp:   74.98s | Confidence: 0.0349 | Prediction: No Fall\n",
      "Timestamp:   75.48s | Confidence: 0.9702 | Prediction: FALL DETECTED!\n",
      "Timestamp:   75.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   76.48s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   76.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   77.48s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   77.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   78.48s | Confidence: 0.9989 | Prediction: FALL DETECTED!\n",
      "Timestamp:   78.98s | Confidence: 0.9926 | Prediction: FALL DETECTED!\n",
      "Timestamp:   79.48s | Confidence: 0.6710 | Prediction: FALL DETECTED!\n",
      "Timestamp:   79.98s | Confidence: 0.9960 | Prediction: FALL DETECTED!\n",
      "Timestamp:   80.48s | Confidence: 0.9992 | Prediction: FALL DETECTED!\n",
      "Timestamp:   80.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   81.48s | Confidence: 0.9996 | Prediction: FALL DETECTED!\n",
      "Timestamp:   81.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   82.48s | Confidence: 0.0006 | Prediction: No Fall\n",
      "Timestamp:   82.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   83.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   83.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   84.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   84.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   85.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   85.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   86.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   86.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   87.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   87.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   88.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   88.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   89.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   89.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   90.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   90.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   91.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   91.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   92.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   92.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   93.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   93.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   94.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   94.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   95.48s | Confidence: 0.0004 | Prediction: No Fall\n",
      "Timestamp:   95.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   96.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:   96.98s | Confidence: 0.0022 | Prediction: No Fall\n",
      "Timestamp:   97.48s | Confidence: 0.0045 | Prediction: No Fall\n",
      "Timestamp:   97.98s | Confidence: 0.9339 | Prediction: FALL DETECTED!\n",
      "Timestamp:   98.48s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   98.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   99.48s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:   99.98s | Confidence: 0.9994 | Prediction: FALL DETECTED!\n",
      "Timestamp:  100.48s | Confidence: 0.2146 | Prediction: No Fall\n",
      "Timestamp:  100.98s | Confidence: 0.0003 | Prediction: No Fall\n",
      "Timestamp:  101.48s | Confidence: 0.0002 | Prediction: No Fall\n",
      "Timestamp:  101.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  102.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  102.98s | Confidence: 0.9994 | Prediction: FALL DETECTED!\n",
      "Timestamp:  103.48s | Confidence: 0.9871 | Prediction: FALL DETECTED!\n",
      "\n",
      "--- Saved 100 features to simulated_features\\features_batch_1.npy ---\n",
      "\n",
      "Timestamp:  103.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:  104.48s | Confidence: 0.9998 | Prediction: FALL DETECTED!\n",
      "Timestamp:  104.98s | Confidence: 0.0565 | Prediction: No Fall\n",
      "Timestamp:  105.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  105.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  106.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  106.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  107.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  107.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  108.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  108.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  109.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  109.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  110.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  110.98s | Confidence: 0.0005 | Prediction: No Fall\n",
      "Timestamp:  111.48s | Confidence: 0.0031 | Prediction: No Fall\n",
      "Timestamp:  111.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  112.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  112.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  113.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  113.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  114.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  114.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  115.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  115.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  116.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  116.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  117.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  117.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  118.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  118.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  119.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  119.98s | Confidence: 0.0562 | Prediction: No Fall\n",
      "Timestamp:  120.48s | Confidence: 0.0042 | Prediction: No Fall\n",
      "Timestamp:  120.98s | Confidence: 0.9511 | Prediction: FALL DETECTED!\n",
      "Timestamp:  121.48s | Confidence: 0.8459 | Prediction: FALL DETECTED!\n",
      "Timestamp:  121.98s | Confidence: 0.0141 | Prediction: No Fall\n",
      "Timestamp:  122.48s | Confidence: 0.3384 | Prediction: No Fall\n",
      "Timestamp:  122.98s | Confidence: 0.0023 | Prediction: No Fall\n",
      "Timestamp:  123.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  123.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  124.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  124.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  125.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  125.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  126.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  126.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  127.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  127.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  128.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  128.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  129.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  129.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  130.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  130.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  131.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  131.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  132.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  132.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  133.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  133.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  134.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  134.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  135.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  135.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  136.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  136.98s | Confidence: 0.0015 | Prediction: No Fall\n",
      "Timestamp:  137.48s | Confidence: 0.7976 | Prediction: FALL DETECTED!\n",
      "Timestamp:  137.98s | Confidence: 0.6642 | Prediction: FALL DETECTED!\n",
      "Timestamp:  138.48s | Confidence: 0.9767 | Prediction: FALL DETECTED!\n",
      "Timestamp:  138.98s | Confidence: 0.9817 | Prediction: FALL DETECTED!\n",
      "Timestamp:  139.48s | Confidence: 0.4687 | Prediction: No Fall\n",
      "Timestamp:  139.98s | Confidence: 0.3217 | Prediction: No Fall\n",
      "Timestamp:  140.48s | Confidence: 0.0010 | Prediction: No Fall\n",
      "Timestamp:  140.98s | Confidence: 0.0002 | Prediction: No Fall\n",
      "Timestamp:  141.48s | Confidence: 0.9892 | Prediction: FALL DETECTED!\n",
      "Timestamp:  141.98s | Confidence: 0.9998 | Prediction: FALL DETECTED!\n",
      "Timestamp:  142.48s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:  142.98s | Confidence: 1.0000 | Prediction: FALL DETECTED!\n",
      "Timestamp:  143.48s | Confidence: 0.9576 | Prediction: FALL DETECTED!\n",
      "Timestamp:  143.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  144.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  144.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  145.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  145.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  146.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  146.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  147.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  147.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  148.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  148.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  149.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  149.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  150.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  150.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  151.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  151.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  152.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  152.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  153.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "\n",
      "--- Saved 100 features to simulated_features\\features_batch_2.npy ---\n",
      "\n",
      "Timestamp:  153.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  154.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  154.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  155.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  155.98s | Confidence: 0.0013 | Prediction: No Fall\n",
      "Timestamp:  156.48s | Confidence: 0.0004 | Prediction: No Fall\n",
      "Timestamp:  156.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  157.48s | Confidence: 0.1364 | Prediction: No Fall\n",
      "Timestamp:  157.98s | Confidence: 0.0053 | Prediction: No Fall\n",
      "Timestamp:  158.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  158.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  159.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  159.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  160.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  160.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  161.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  161.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  162.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  162.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  163.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  163.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  164.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  164.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  165.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  165.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  166.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  166.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  167.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  167.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  168.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  168.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  169.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  169.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  170.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  170.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  171.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  171.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  172.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  172.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  173.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  173.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  174.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  174.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  175.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  175.98s | Confidence: 0.0002 | Prediction: No Fall\n",
      "Timestamp:  176.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  176.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  177.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  177.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  178.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  178.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  179.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  179.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  180.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  180.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  181.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  181.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  182.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  182.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  183.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  183.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  184.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  184.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  185.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  185.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  186.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  186.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  187.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  187.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  188.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  188.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  189.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  189.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  190.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  190.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  191.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  191.98s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  192.48s | Confidence: 0.0000 | Prediction: No Fall\n",
      "Timestamp:  192.98s | Confidence: 0.9675 | Prediction: FALL DETECTED!\n",
      "Timestamp:  193.48s | Confidence: 0.9958 | Prediction: FALL DETECTED!\n",
      "\n",
      "--- Saved 80 features to simulated_features\\features_batch_3.npy ---\n",
      "\n",
      "Simulation finished. All remaining features saved.\n",
      "\n",
      "Total simulation time: 1.77 seconds.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. 配置参数 ---\n",
    "SAMPLING_RATE_HZ = 50\n",
    "WINDOW_SECONDS = 4\n",
    "STEP_SECONDS = 0.5 # 每隔0.5秒进行一次判断\n",
    "\n",
    "WINDOW_SIZE = SAMPLING_RATE_HZ * WINDOW_SECONDS # 200 个数据点\n",
    "STEP_SIZE = int(SAMPLING_RATE_HZ * STEP_SECONDS) # 25 个数据点\n",
    "\n",
    "MODEL_PATH = \"feature_model_1dcnn.pth\"\n",
    "SCALER_PATH = \"scaler_50hz_torch.gz\"\n",
    "FEATURE_OUTPUT_DIR = \"simulated_features\"\n",
    "FEATURE_BATCH_SIZE = 100 # 每100个特征保存一次文件\n",
    "\n",
    "# --- 2. 加载资源 ---\n",
    "print(\"Loading model and scaler...\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 加载模型\n",
    "model = FeatureModel1DCNN(input_channels=11, num_classes=1).to(device)\n",
    "# 如果文件不存在，则跳过加载，使用随机初始化的模型进行模拟\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "    print(f\"Model loaded from {MODEL_PATH}\")\n",
    "else:\n",
    "    print(f\"Warning: Model file not found at {MODEL_PATH}. Using a randomly initialized model.\")\n",
    "model.eval()\n",
    "\n",
    "# 加载标准化器\n",
    "if os.path.exists(SCALER_PATH):\n",
    "    scaler = joblib.load(SCALER_PATH)\n",
    "    print(f\"Scaler loaded from {SCALER_PATH}\")\n",
    "else:\n",
    "    # 如果找不到，创建一个虚拟的scaler\n",
    "    print(f\"Warning: Scaler file not found at {SCALER_PATH}. Using a dummy scaler.\")\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "# --- 3. 加载数据 ---\n",
    "print(\"Loading sequence data...\")\n",
    "try:\n",
    "    # 尝试加载真实数据（如果存在）\n",
    "    all_sequences = X_sequences\n",
    "except:\n",
    "    print(\"Sequence data file not found. Generating random data for simulation.\")\n",
    "    all_sequences = np.random.rand(9491, 200, 11)\n",
    "\n",
    "\n",
    "\n",
    "# --- 4. 运行模拟 ---\n",
    "print(\"\\nStarting real-time simulation...\")\n",
    "data_source = DataSourceSimulator(all_sequences, sampling_rate_hz=SAMPLING_RATE_HZ)\n",
    "edge_node = EdgeNodeSimulator(\n",
    "    model, scaler, device, \n",
    "    window_size=WINDOW_SIZE, \n",
    "    step_size=STEP_SIZE, \n",
    "    feature_batch_size=FEATURE_BATCH_SIZE,\n",
    "    output_dir=FEATURE_OUTPUT_DIR\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for timestamp, data_point in data_source:\n",
    "    edge_node.process_data_point(timestamp, data_point)\n",
    "    # 可以加入一个小的延时来模拟实时，但对于纯模拟可以注释掉\n",
    "    # time.sleep(0.001) \n",
    "\n",
    "# 结束时，保存最后一批不满的特征\n",
    "edge_node.finalize()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\nTotal simulation time: {end_time - start_time:.2f} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "falldetect_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
